{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f47ac3f-fba2-41fa-842e-8892bda9e093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch,torchvision\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import os, json, cv2, random\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor,DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.structures import BoxMode\n",
    "from tqdm import tqdm\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cfb9445-876d-4218-a102-395cd71e9c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bad0dfb6-bfa3-4d79-91f2-6526fe2d3aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vid_4_1000.jpg</td>\n",
       "      <td>281.259045</td>\n",
       "      <td>187.035071</td>\n",
       "      <td>327.727931</td>\n",
       "      <td>223.225547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vid_4_10000.jpg</td>\n",
       "      <td>15.163531</td>\n",
       "      <td>187.035071</td>\n",
       "      <td>120.329957</td>\n",
       "      <td>236.430180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vid_4_10040.jpg</td>\n",
       "      <td>239.192475</td>\n",
       "      <td>176.764801</td>\n",
       "      <td>361.968162</td>\n",
       "      <td>236.430180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vid_4_10020.jpg</td>\n",
       "      <td>496.483358</td>\n",
       "      <td>172.363256</td>\n",
       "      <td>630.020260</td>\n",
       "      <td>231.539575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vid_4_10060.jpg</td>\n",
       "      <td>16.630970</td>\n",
       "      <td>186.546010</td>\n",
       "      <td>132.558611</td>\n",
       "      <td>238.386422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>vid_4_9860.jpg</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>198.321729</td>\n",
       "      <td>49.235251</td>\n",
       "      <td>236.223284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>vid_4_9880.jpg</td>\n",
       "      <td>329.876184</td>\n",
       "      <td>156.482351</td>\n",
       "      <td>536.664239</td>\n",
       "      <td>250.497895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>vid_4_9900.jpg</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>168.295823</td>\n",
       "      <td>141.797524</td>\n",
       "      <td>239.176652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>vid_4_9960.jpg</td>\n",
       "      <td>487.428988</td>\n",
       "      <td>172.233646</td>\n",
       "      <td>616.917699</td>\n",
       "      <td>228.839864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>vid_4_9980.jpg</td>\n",
       "      <td>221.558631</td>\n",
       "      <td>182.570434</td>\n",
       "      <td>348.585579</td>\n",
       "      <td>238.192196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>559 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               image        xmin        ymin        xmax        ymax\n",
       "0     vid_4_1000.jpg  281.259045  187.035071  327.727931  223.225547\n",
       "1    vid_4_10000.jpg   15.163531  187.035071  120.329957  236.430180\n",
       "2    vid_4_10040.jpg  239.192475  176.764801  361.968162  236.430180\n",
       "3    vid_4_10020.jpg  496.483358  172.363256  630.020260  231.539575\n",
       "4    vid_4_10060.jpg   16.630970  186.546010  132.558611  238.386422\n",
       "..               ...         ...         ...         ...         ...\n",
       "554   vid_4_9860.jpg    0.000000  198.321729   49.235251  236.223284\n",
       "555   vid_4_9880.jpg  329.876184  156.482351  536.664239  250.497895\n",
       "556   vid_4_9900.jpg    0.000000  168.295823  141.797524  239.176652\n",
       "557   vid_4_9960.jpg  487.428988  172.233646  616.917699  228.839864\n",
       "558   vid_4_9980.jpg  221.558631  182.570434  348.585579  238.192196\n",
       "\n",
       "[559 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68763bcb-d5a7-4d50-8bd3-d6f3629ff057",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = {'instances':{'pred_classes':[],'pred_boxes':[]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1ac0eec-7079-4887-a653-d4f30525fe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred['instances'].pred_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65a7cd00-a132-4fce-baa0-f4ec2270ff04",
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin,ymin,xmax,ymax = 281,187,327,223"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9354a4f-f262-4335-b0ba-09a588389b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = xmin\n",
    "y = ymin\n",
    "w = xmax - xmin\n",
    "h = ymax - ymin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40de1472-f35b-4a37-9b79-ead481a705c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = cv2.imread('./data/vid_4_1000.jpg')\n",
    "roi=im[y:y+h,x:x+w]\n",
    "cv2.imwrite(str('crop') + '.jpg', roi)\n",
    "cv2.rectangle(im,(x,y),(x+w,y+h),(200,0,0),2)\n",
    "cv2.imwrite(str('box') + '.jpg', im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63d00698-931c-413f-92bf-1b4f85bb0708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vid_4_1000.jpg</td>\n",
       "      <td>281.259045</td>\n",
       "      <td>187.035071</td>\n",
       "      <td>327.727931</td>\n",
       "      <td>223.225547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vid_4_10000.jpg</td>\n",
       "      <td>15.163531</td>\n",
       "      <td>187.035071</td>\n",
       "      <td>120.329957</td>\n",
       "      <td>236.430180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vid_4_10040.jpg</td>\n",
       "      <td>239.192475</td>\n",
       "      <td>176.764801</td>\n",
       "      <td>361.968162</td>\n",
       "      <td>236.430180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vid_4_10020.jpg</td>\n",
       "      <td>496.483358</td>\n",
       "      <td>172.363256</td>\n",
       "      <td>630.020260</td>\n",
       "      <td>231.539575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vid_4_10060.jpg</td>\n",
       "      <td>16.630970</td>\n",
       "      <td>186.546010</td>\n",
       "      <td>132.558611</td>\n",
       "      <td>238.386422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>vid_4_9860.jpg</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>198.321729</td>\n",
       "      <td>49.235251</td>\n",
       "      <td>236.223284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>vid_4_9880.jpg</td>\n",
       "      <td>329.876184</td>\n",
       "      <td>156.482351</td>\n",
       "      <td>536.664239</td>\n",
       "      <td>250.497895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>vid_4_9900.jpg</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>168.295823</td>\n",
       "      <td>141.797524</td>\n",
       "      <td>239.176652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>vid_4_9960.jpg</td>\n",
       "      <td>487.428988</td>\n",
       "      <td>172.233646</td>\n",
       "      <td>616.917699</td>\n",
       "      <td>228.839864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>vid_4_9980.jpg</td>\n",
       "      <td>221.558631</td>\n",
       "      <td>182.570434</td>\n",
       "      <td>348.585579</td>\n",
       "      <td>238.192196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>559 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               image        xmin        ymin        xmax        ymax\n",
       "0     vid_4_1000.jpg  281.259045  187.035071  327.727931  223.225547\n",
       "1    vid_4_10000.jpg   15.163531  187.035071  120.329957  236.430180\n",
       "2    vid_4_10040.jpg  239.192475  176.764801  361.968162  236.430180\n",
       "3    vid_4_10020.jpg  496.483358  172.363256  630.020260  231.539575\n",
       "4    vid_4_10060.jpg   16.630970  186.546010  132.558611  238.386422\n",
       "..               ...         ...         ...         ...         ...\n",
       "554   vid_4_9860.jpg    0.000000  198.321729   49.235251  236.223284\n",
       "555   vid_4_9880.jpg  329.876184  156.482351  536.664239  250.497895\n",
       "556   vid_4_9900.jpg    0.000000  168.295823  141.797524  239.176652\n",
       "557   vid_4_9960.jpg  487.428988  172.233646  616.917699  228.839864\n",
       "558   vid_4_9980.jpg  221.558631  182.570434  348.585579  238.192196\n",
       "\n",
       "[559 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "488df11f-bb8d-46d5-86b0-40899dbc8cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    new_data = []\n",
    "    idx = len(data)\n",
    "    for i in tqdm(range(idx)):\n",
    "        record = {}\n",
    "        info = data.iloc[i]\n",
    "        img_path = f'./data/{info[\"image\"]}'\n",
    "        img = cv2.imread(f'./data/{info[\"image\"]}')\n",
    "        img = img / 255.0\n",
    "        record['file_name'] = img_path\n",
    "        record['image_id'] = i\n",
    "        record['height'],record['width'] = img.shape[:2]\n",
    "        objs = [{\n",
    "            'bbox':[xmin,ymin,xmax,ymax],\n",
    "            'bbox_mode':BoxMode.XYXY_ABS,\n",
    "            'category_id':0\n",
    "        }]\n",
    "        record['annotations'] = objs\n",
    "        new_data.append(record)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d107512c-7d8d-499a-a37d-a0728feddb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['car']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e28cbab-986d-4172-baa4-2c4ea7ce142c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DatasetCatalog.register('data',lambda : load_data())\n",
    "MetadataCatalog.get('data').set(thing_classes=labels)\n",
    "metadata = MetadataCatalog.get('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63a972f3-7d0d-4eb3-b41b-32f1469bfa2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-11 15:46:15.700100: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mranuga-d\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.4 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20211011_154617-1r73t36y\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbaseline\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/ranuga-d/Car-Object-Detection-Learning-Detectron2-V2\" target=\"_blank\">https://app.wandb.ai/ranuga-d/Car-Object-Detection-Learning-Detectron2-V2</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/ranuga-d/Car-Object-Detection-Learning-Detectron2-V2/runs/1r73t36y\" target=\"_blank\">https://app.wandb.ai/ranuga-d/Car-Object-Detection-Learning-Detectron2-V2/runs/1r73t36y</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m[10/11 15:46:33 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): ResNet(\n",
      "    (stem): BasicStem(\n",
      "      (conv1): Conv2d(\n",
      "        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "      )\n",
      "    )\n",
      "    (res2): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res3): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (3): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res4): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (3): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (4): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (5): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (6): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (7): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (8): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (9): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (10): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (11): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (12): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (13): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (14): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (15): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (16): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (17): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (18): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (19): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (20): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (21): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (22): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): Res5ROIHeads(\n",
      "    (pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (res5): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=2048, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=2048, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 559/559 [00:02<00:00, 233.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/11 15:46:35 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 559 images left.\n",
      "\u001b[32m[10/11 15:46:35 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|    car     | 559          |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[10/11 15:46:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[10/11 15:46:35 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/11 15:46:35 d2.data.common]: \u001b[0mSerializing 559 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/11 15:46:35 d2.data.common]: \u001b[0mSerialized dataset takes 0.19 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 2048) in the checkpoint but (2, 2048) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 2048) in the checkpoint but (4, 2048) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mproposal_generator.anchor_generator.cell_anchors.0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/11 15:46:36 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/11 15:46:48 d2.utils.events]: \u001b[0m eta: 0:23:34  iter: 19  total_loss: 0.8574  loss_cls: 0.7535  loss_box_reg: 0.03398  loss_rpn_cls: 0.04717  loss_rpn_loc: 0.003807  time: 0.5675  data_time: 0.0140  lr: 4.9953e-06  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:46:59 d2.utils.events]: \u001b[0m eta: 0:23:00  iter: 39  total_loss: 0.7439  loss_cls: 0.6396  loss_box_reg: 0.03539  loss_rpn_cls: 0.04951  loss_rpn_loc: 0.003864  time: 0.5626  data_time: 0.0033  lr: 9.9902e-06  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:47:10 d2.utils.events]: \u001b[0m eta: 0:22:41  iter: 59  total_loss: 0.5374  loss_cls: 0.4656  loss_box_reg: 0.000559  loss_rpn_cls: 0.05131  loss_rpn_loc: 0.003837  time: 0.5565  data_time: 0.0030  lr: 1.4985e-05  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:47:21 d2.utils.events]: \u001b[0m eta: 0:22:29  iter: 79  total_loss: 0.3946  loss_cls: 0.303  loss_box_reg: 0.02881  loss_rpn_cls: 0.04633  loss_rpn_loc: 0.002917  time: 0.5560  data_time: 0.0028  lr: 1.998e-05  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:47:32 d2.utils.events]: \u001b[0m eta: 0:22:18  iter: 99  total_loss: 0.2952  loss_cls: 0.2167  loss_box_reg: 0.0004232  loss_rpn_cls: 0.05223  loss_rpn_loc: 0.003063  time: 0.5557  data_time: 0.0029  lr: 2.4975e-05  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:47:43 d2.utils.events]: \u001b[0m eta: 0:21:54  iter: 119  total_loss: 0.2386  loss_cls: 0.1563  loss_box_reg: 0.01637  loss_rpn_cls: 0.05817  loss_rpn_loc: 0.004357  time: 0.5518  data_time: 0.0028  lr: 2.997e-05  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:47:54 d2.utils.events]: \u001b[0m eta: 0:21:42  iter: 139  total_loss: 0.1807  loss_cls: 0.1162  loss_box_reg: 0.0004727  loss_rpn_cls: 0.04592  loss_rpn_loc: 0.003315  time: 0.5490  data_time: 0.0026  lr: 3.4965e-05  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:48:04 d2.utils.events]: \u001b[0m eta: 0:21:25  iter: 159  total_loss: 0.1679  loss_cls: 0.0966  loss_box_reg: 0.01302  loss_rpn_cls: 0.04697  loss_rpn_loc: 0.00281  time: 0.5427  data_time: 0.0026  lr: 3.996e-05  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:48:14 d2.utils.events]: \u001b[0m eta: 0:21:08  iter: 179  total_loss: 0.1683  loss_cls: 0.09232  loss_box_reg: 0.02915  loss_rpn_cls: 0.04564  loss_rpn_loc: 0.00363  time: 0.5400  data_time: 0.0026  lr: 4.4955e-05  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:48:24 d2.utils.events]: \u001b[0m eta: 0:20:53  iter: 199  total_loss: 0.1391  loss_cls: 0.07668  loss_box_reg: 0.0002558  loss_rpn_cls: 0.04974  loss_rpn_loc: 0.002539  time: 0.5375  data_time: 0.0027  lr: 4.995e-05  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:48:34 d2.utils.events]: \u001b[0m eta: 0:20:32  iter: 219  total_loss: 0.1716  loss_cls: 0.06972  loss_box_reg: 0.009267  loss_rpn_cls: 0.0515  loss_rpn_loc: 0.00346  time: 0.5332  data_time: 0.0026  lr: 5.4945e-05  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:48:44 d2.utils.events]: \u001b[0m eta: 0:20:13  iter: 239  total_loss: 0.1879  loss_cls: 0.08675  loss_box_reg: 0.04186  loss_rpn_cls: 0.05032  loss_rpn_loc: 0.003688  time: 0.5292  data_time: 0.0028  lr: 5.994e-05  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:48:54 d2.utils.events]: \u001b[0m eta: 0:19:49  iter: 259  total_loss: 0.1958  loss_cls: 0.09987  loss_box_reg: 0.05659  loss_rpn_cls: 0.04585  loss_rpn_loc: 0.003181  time: 0.5263  data_time: 0.0028  lr: 6.4935e-05  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:49:04 d2.utils.events]: \u001b[0m eta: 0:19:17  iter: 279  total_loss: 0.1304  loss_cls: 0.0656  loss_box_reg: 0.0002966  loss_rpn_cls: 0.0453  loss_rpn_loc: 0.002177  time: 0.5232  data_time: 0.0028  lr: 6.993e-05  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:49:14 d2.utils.events]: \u001b[0m eta: 0:19:02  iter: 299  total_loss: 0.2281  loss_cls: 0.1012  loss_box_reg: 0.06408  loss_rpn_cls: 0.04517  loss_rpn_loc: 0.002252  time: 0.5223  data_time: 0.0025  lr: 7.4925e-05  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:49:24 d2.utils.events]: \u001b[0m eta: 0:18:42  iter: 319  total_loss: 0.2394  loss_cls: 0.111  loss_box_reg: 0.08086  loss_rpn_cls: 0.04026  loss_rpn_loc: 0.002423  time: 0.5207  data_time: 0.0027  lr: 7.992e-05  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:49:34 d2.utils.events]: \u001b[0m eta: 0:18:24  iter: 339  total_loss: 0.1918  loss_cls: 0.09516  loss_box_reg: 0.05637  loss_rpn_cls: 0.03227  loss_rpn_loc: 0.002063  time: 0.5189  data_time: 0.0026  lr: 8.4915e-05  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:49:43 d2.utils.events]: \u001b[0m eta: 0:18:10  iter: 359  total_loss: 0.2524  loss_cls: 0.117  loss_box_reg: 0.09854  loss_rpn_cls: 0.03502  loss_rpn_loc: 0.00225  time: 0.5170  data_time: 0.0025  lr: 8.991e-05  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:49:53 d2.utils.events]: \u001b[0m eta: 0:17:55  iter: 379  total_loss: 0.2499  loss_cls: 0.114  loss_box_reg: 0.0917  loss_rpn_cls: 0.03583  loss_rpn_loc: 0.002458  time: 0.5157  data_time: 0.0025  lr: 9.4905e-05  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:50:03 d2.utils.events]: \u001b[0m eta: 0:17:42  iter: 399  total_loss: 0.2266  loss_cls: 0.1106  loss_box_reg: 0.0677  loss_rpn_cls: 0.03523  loss_rpn_loc: 0.00248  time: 0.5143  data_time: 0.0026  lr: 9.99e-05  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:50:13 d2.utils.events]: \u001b[0m eta: 0:17:27  iter: 419  total_loss: 0.2651  loss_cls: 0.1306  loss_box_reg: 0.09562  loss_rpn_cls: 0.0312  loss_rpn_loc: 0.002173  time: 0.5131  data_time: 0.0025  lr: 0.0001049  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:50:22 d2.utils.events]: \u001b[0m eta: 0:17:13  iter: 439  total_loss: 0.3088  loss_cls: 0.1364  loss_box_reg: 0.1249  loss_rpn_cls: 0.03268  loss_rpn_loc: 0.002879  time: 0.5118  data_time: 0.0026  lr: 0.00010989  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:50:32 d2.utils.events]: \u001b[0m eta: 0:16:58  iter: 459  total_loss: 0.3065  loss_cls: 0.1444  loss_box_reg: 0.1286  loss_rpn_cls: 0.02748  loss_rpn_loc: 0.002058  time: 0.5102  data_time: 0.0026  lr: 0.00011489  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:50:42 d2.utils.events]: \u001b[0m eta: 0:16:46  iter: 479  total_loss: 0.3251  loss_cls: 0.1446  loss_box_reg: 0.1536  loss_rpn_cls: 0.02647  loss_rpn_loc: 0.001914  time: 0.5093  data_time: 0.0026  lr: 0.00011988  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:50:52 d2.utils.events]: \u001b[0m eta: 0:16:35  iter: 499  total_loss: 0.3266  loss_cls: 0.1454  loss_box_reg: 0.1466  loss_rpn_cls: 0.02084  loss_rpn_loc: 0.001759  time: 0.5085  data_time: 0.0025  lr: 0.00012488  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:51:01 d2.utils.events]: \u001b[0m eta: 0:16:24  iter: 519  total_loss: 0.3477  loss_cls: 0.1545  loss_box_reg: 0.1645  loss_rpn_cls: 0.02503  loss_rpn_loc: 0.001983  time: 0.5078  data_time: 0.0026  lr: 0.00012987  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:51:11 d2.utils.events]: \u001b[0m eta: 0:16:14  iter: 539  total_loss: 0.3927  loss_cls: 0.1636  loss_box_reg: 0.2008  loss_rpn_cls: 0.01854  loss_rpn_loc: 0.001812  time: 0.5071  data_time: 0.0027  lr: 0.00013487  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:51:21 d2.utils.events]: \u001b[0m eta: 0:16:03  iter: 559  total_loss: 0.3918  loss_cls: 0.1642  loss_box_reg: 0.1914  loss_rpn_cls: 0.02398  loss_rpn_loc: 0.002275  time: 0.5067  data_time: 0.0026  lr: 0.00013986  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:51:31 d2.utils.events]: \u001b[0m eta: 0:15:53  iter: 579  total_loss: 0.4001  loss_cls: 0.1713  loss_box_reg: 0.2042  loss_rpn_cls: 0.01626  loss_rpn_loc: 0.001629  time: 0.5063  data_time: 0.0025  lr: 0.00014486  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:51:41 d2.utils.events]: \u001b[0m eta: 0:15:43  iter: 599  total_loss: 0.4422  loss_cls: 0.1813  loss_box_reg: 0.2531  loss_rpn_cls: 0.01504  loss_rpn_loc: 0.001671  time: 0.5058  data_time: 0.0025  lr: 0.00014985  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:51:51 d2.utils.events]: \u001b[0m eta: 0:15:33  iter: 619  total_loss: 0.4279  loss_cls: 0.1756  loss_box_reg: 0.2352  loss_rpn_cls: 0.01514  loss_rpn_loc: 0.001569  time: 0.5052  data_time: 0.0027  lr: 0.00015485  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:52:01 d2.utils.events]: \u001b[0m eta: 0:15:23  iter: 639  total_loss: 0.4443  loss_cls: 0.1926  loss_box_reg: 0.2439  loss_rpn_cls: 0.01582  loss_rpn_loc: 0.001591  time: 0.5047  data_time: 0.0026  lr: 0.00015984  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:52:11 d2.utils.events]: \u001b[0m eta: 0:15:13  iter: 659  total_loss: 0.4717  loss_cls: 0.1941  loss_box_reg: 0.2701  loss_rpn_cls: 0.01449  loss_rpn_loc: 0.001733  time: 0.5044  data_time: 0.0027  lr: 0.00016484  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:52:20 d2.utils.events]: \u001b[0m eta: 0:15:03  iter: 679  total_loss: 0.4596  loss_cls: 0.1918  loss_box_reg: 0.2525  loss_rpn_cls: 0.0144  loss_rpn_loc: 0.00128  time: 0.5039  data_time: 0.0026  lr: 0.00016983  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:52:30 d2.utils.events]: \u001b[0m eta: 0:14:52  iter: 699  total_loss: 0.5237  loss_cls: 0.204  loss_box_reg: 0.3146  loss_rpn_cls: 0.01546  loss_rpn_loc: 0.001614  time: 0.5033  data_time: 0.0025  lr: 0.00017483  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:52:40 d2.utils.events]: \u001b[0m eta: 0:14:42  iter: 719  total_loss: 0.4996  loss_cls: 0.1983  loss_box_reg: 0.2824  loss_rpn_cls: 0.01859  loss_rpn_loc: 0.001448  time: 0.5028  data_time: 0.0025  lr: 0.00017982  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:52:50 d2.utils.events]: \u001b[0m eta: 0:14:32  iter: 739  total_loss: 0.5276  loss_cls: 0.2023  loss_box_reg: 0.3196  loss_rpn_cls: 0.009818  loss_rpn_loc: 0.001458  time: 0.5024  data_time: 0.0025  lr: 0.00018482  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:52:59 d2.utils.events]: \u001b[0m eta: 0:14:22  iter: 759  total_loss: 0.5227  loss_cls: 0.2007  loss_box_reg: 0.3052  loss_rpn_cls: 0.01023  loss_rpn_loc: 0.001523  time: 0.5019  data_time: 0.0025  lr: 0.00018981  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:53:09 d2.utils.events]: \u001b[0m eta: 0:14:12  iter: 779  total_loss: 0.5498  loss_cls: 0.2043  loss_box_reg: 0.3107  loss_rpn_cls: 0.008389  loss_rpn_loc: 0.001658  time: 0.5016  data_time: 0.0026  lr: 0.00019481  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:53:19 d2.utils.events]: \u001b[0m eta: 0:14:02  iter: 799  total_loss: 0.5855  loss_cls: 0.2161  loss_box_reg: 0.3453  loss_rpn_cls: 0.009781  loss_rpn_loc: 0.001145  time: 0.5013  data_time: 0.0026  lr: 0.0001998  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:53:29 d2.utils.events]: \u001b[0m eta: 0:13:52  iter: 819  total_loss: 0.5259  loss_cls: 0.2132  loss_box_reg: 0.3035  loss_rpn_cls: 0.01225  loss_rpn_loc: 0.001109  time: 0.5019  data_time: 0.0031  lr: 0.0002048  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:53:40 d2.utils.events]: \u001b[0m eta: 0:13:42  iter: 839  total_loss: 0.5423  loss_cls: 0.1946  loss_box_reg: 0.3307  loss_rpn_cls: 0.0118  loss_rpn_loc: 0.001327  time: 0.5023  data_time: 0.0027  lr: 0.00020979  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:53:49 d2.utils.events]: \u001b[0m eta: 0:13:32  iter: 859  total_loss: 0.5148  loss_cls: 0.1915  loss_box_reg: 0.3119  loss_rpn_cls: 0.009883  loss_rpn_loc: 0.001683  time: 0.5019  data_time: 0.0026  lr: 0.00021479  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:53:59 d2.utils.events]: \u001b[0m eta: 0:13:22  iter: 879  total_loss: 0.5732  loss_cls: 0.2024  loss_box_reg: 0.3471  loss_rpn_cls: 0.00906  loss_rpn_loc: 0.001334  time: 0.5017  data_time: 0.0026  lr: 0.00021978  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:54:10 d2.utils.events]: \u001b[0m eta: 0:13:13  iter: 899  total_loss: 0.5629  loss_cls: 0.2148  loss_box_reg: 0.3232  loss_rpn_cls: 0.01008  loss_rpn_loc: 0.001722  time: 0.5019  data_time: 0.0028  lr: 0.00022478  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:54:20 d2.utils.events]: \u001b[0m eta: 0:13:03  iter: 919  total_loss: 0.5494  loss_cls: 0.1867  loss_box_reg: 0.3465  loss_rpn_cls: 0.01067  loss_rpn_loc: 0.0009038  time: 0.5023  data_time: 0.0027  lr: 0.00022977  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:54:30 d2.utils.events]: \u001b[0m eta: 0:12:53  iter: 939  total_loss: 0.513  loss_cls: 0.2026  loss_box_reg: 0.301  loss_rpn_cls: 0.01054  loss_rpn_loc: 0.001584  time: 0.5021  data_time: 0.0027  lr: 0.00023477  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:54:40 d2.utils.events]: \u001b[0m eta: 0:12:43  iter: 959  total_loss: 0.5601  loss_cls: 0.2024  loss_box_reg: 0.3297  loss_rpn_cls: 0.0095  loss_rpn_loc: 0.001499  time: 0.5018  data_time: 0.0027  lr: 0.00023976  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:54:50 d2.utils.events]: \u001b[0m eta: 0:12:33  iter: 979  total_loss: 0.5133  loss_cls: 0.1979  loss_box_reg: 0.2957  loss_rpn_cls: 0.0104  loss_rpn_loc: 0.001794  time: 0.5017  data_time: 0.0026  lr: 0.00024476  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:54:59 d2.utils.events]: \u001b[0m eta: 0:12:23  iter: 999  total_loss: 0.5453  loss_cls: 0.2034  loss_box_reg: 0.3215  loss_rpn_cls: 0.006906  loss_rpn_loc: 0.001108  time: 0.5015  data_time: 0.0027  lr: 0.00024975  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:55:10 d2.utils.events]: \u001b[0m eta: 0:12:13  iter: 1019  total_loss: 0.5836  loss_cls: 0.218  loss_box_reg: 0.3515  loss_rpn_cls: 0.0103  loss_rpn_loc: 0.001227  time: 0.5014  data_time: 0.0026  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:55:19 d2.utils.events]: \u001b[0m eta: 0:12:03  iter: 1039  total_loss: 0.5473  loss_cls: 0.1973  loss_box_reg: 0.3312  loss_rpn_cls: 0.007635  loss_rpn_loc: 0.001254  time: 0.5012  data_time: 0.0026  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:55:29 d2.utils.events]: \u001b[0m eta: 0:11:52  iter: 1059  total_loss: 0.5563  loss_cls: 0.2103  loss_box_reg: 0.3358  loss_rpn_cls: 0.005936  loss_rpn_loc: 0.001252  time: 0.5009  data_time: 0.0026  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:55:39 d2.utils.events]: \u001b[0m eta: 0:11:42  iter: 1079  total_loss: 0.545  loss_cls: 0.2058  loss_box_reg: 0.3358  loss_rpn_cls: 0.01077  loss_rpn_loc: 0.001418  time: 0.5009  data_time: 0.0025  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:55:49 d2.utils.events]: \u001b[0m eta: 0:11:32  iter: 1099  total_loss: 0.5303  loss_cls: 0.196  loss_box_reg: 0.3177  loss_rpn_cls: 0.008226  loss_rpn_loc: 0.00141  time: 0.5009  data_time: 0.0026  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:55:59 d2.utils.events]: \u001b[0m eta: 0:11:22  iter: 1119  total_loss: 0.6221  loss_cls: 0.2182  loss_box_reg: 0.3587  loss_rpn_cls: 0.00822  loss_rpn_loc: 0.00157  time: 0.5006  data_time: 0.0026  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:56:09 d2.utils.events]: \u001b[0m eta: 0:11:12  iter: 1139  total_loss: 0.5384  loss_cls: 0.208  loss_box_reg: 0.3242  loss_rpn_cls: 0.005559  loss_rpn_loc: 0.001395  time: 0.5006  data_time: 0.0026  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:56:19 d2.utils.events]: \u001b[0m eta: 0:11:02  iter: 1159  total_loss: 0.5308  loss_cls: 0.2065  loss_box_reg: 0.3273  loss_rpn_cls: 0.007408  loss_rpn_loc: 0.001565  time: 0.5007  data_time: 0.0028  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:56:29 d2.utils.events]: \u001b[0m eta: 0:10:52  iter: 1179  total_loss: 0.5302  loss_cls: 0.1912  loss_box_reg: 0.3409  loss_rpn_cls: 0.007454  loss_rpn_loc: 0.001531  time: 0.5008  data_time: 0.0026  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:56:40 d2.utils.events]: \u001b[0m eta: 0:10:42  iter: 1199  total_loss: 0.5343  loss_cls: 0.1991  loss_box_reg: 0.3287  loss_rpn_cls: 0.006573  loss_rpn_loc: 0.001145  time: 0.5010  data_time: 0.0029  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:56:50 d2.utils.events]: \u001b[0m eta: 0:10:32  iter: 1219  total_loss: 0.5272  loss_cls: 0.1962  loss_box_reg: 0.3136  loss_rpn_cls: 0.007447  loss_rpn_loc: 0.001458  time: 0.5012  data_time: 0.0025  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:57:00 d2.utils.events]: \u001b[0m eta: 0:10:23  iter: 1239  total_loss: 0.5039  loss_cls: 0.1896  loss_box_reg: 0.3043  loss_rpn_cls: 0.008359  loss_rpn_loc: 0.001359  time: 0.5011  data_time: 0.0025  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:57:10 d2.utils.events]: \u001b[0m eta: 0:10:13  iter: 1259  total_loss: 0.5391  loss_cls: 0.2044  loss_box_reg: 0.3161  loss_rpn_cls: 0.007774  loss_rpn_loc: 0.001001  time: 0.5010  data_time: 0.0025  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:57:20 d2.utils.events]: \u001b[0m eta: 0:10:03  iter: 1279  total_loss: 0.4934  loss_cls: 0.1731  loss_box_reg: 0.3003  loss_rpn_cls: 0.00511  loss_rpn_loc: 0.001281  time: 0.5011  data_time: 0.0028  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:57:30 d2.utils.events]: \u001b[0m eta: 0:09:53  iter: 1299  total_loss: 0.4738  loss_cls: 0.1769  loss_box_reg: 0.2903  loss_rpn_cls: 0.00532  loss_rpn_loc: 0.001425  time: 0.5015  data_time: 0.0025  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:57:41 d2.utils.events]: \u001b[0m eta: 0:09:43  iter: 1319  total_loss: 0.4696  loss_cls: 0.1917  loss_box_reg: 0.2672  loss_rpn_cls: 0.006045  loss_rpn_loc: 0.001047  time: 0.5017  data_time: 0.0028  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:57:51 d2.utils.events]: \u001b[0m eta: 0:09:34  iter: 1339  total_loss: 0.4551  loss_cls: 0.1737  loss_box_reg: 0.2738  loss_rpn_cls: 0.006305  loss_rpn_loc: 0.001554  time: 0.5019  data_time: 0.0026  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:58:02 d2.utils.events]: \u001b[0m eta: 0:09:24  iter: 1359  total_loss: 0.5196  loss_cls: 0.1915  loss_box_reg: 0.3076  loss_rpn_cls: 0.006264  loss_rpn_loc: 0.001123  time: 0.5022  data_time: 0.0028  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:58:12 d2.utils.events]: \u001b[0m eta: 0:09:14  iter: 1379  total_loss: 0.475  loss_cls: 0.1929  loss_box_reg: 0.297  loss_rpn_cls: 0.006437  loss_rpn_loc: 0.001099  time: 0.5022  data_time: 0.0026  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:58:22 d2.utils.events]: \u001b[0m eta: 0:09:04  iter: 1399  total_loss: 0.4936  loss_cls: 0.1684  loss_box_reg: 0.3034  loss_rpn_cls: 0.006405  loss_rpn_loc: 0.0013  time: 0.5023  data_time: 0.0025  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:58:32 d2.utils.events]: \u001b[0m eta: 0:08:55  iter: 1419  total_loss: 0.4788  loss_cls: 0.1809  loss_box_reg: 0.2875  loss_rpn_cls: 0.005173  loss_rpn_loc: 0.001363  time: 0.5025  data_time: 0.0027  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:58:43 d2.utils.events]: \u001b[0m eta: 0:08:45  iter: 1439  total_loss: 0.4674  loss_cls: 0.1741  loss_box_reg: 0.2706  loss_rpn_cls: 0.00511  loss_rpn_loc: 0.001559  time: 0.5028  data_time: 0.0027  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:58:53 d2.utils.events]: \u001b[0m eta: 0:08:36  iter: 1459  total_loss: 0.503  loss_cls: 0.194  loss_box_reg: 0.3014  loss_rpn_cls: 0.005362  loss_rpn_loc: 0.001172  time: 0.5029  data_time: 0.0026  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:59:02 d2.utils.events]: \u001b[0m eta: 0:08:26  iter: 1479  total_loss: 0.4962  loss_cls: 0.1761  loss_box_reg: 0.3082  loss_rpn_cls: 0.005082  loss_rpn_loc: 0.001393  time: 0.5026  data_time: 0.0026  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:59:12 d2.utils.events]: \u001b[0m eta: 0:08:16  iter: 1499  total_loss: 0.4702  loss_cls: 0.1684  loss_box_reg: 0.2963  loss_rpn_cls: 0.004504  loss_rpn_loc: 0.0008633  time: 0.5025  data_time: 0.0029  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:59:22 d2.utils.events]: \u001b[0m eta: 0:08:06  iter: 1519  total_loss: 0.4909  loss_cls: 0.1755  loss_box_reg: 0.2974  loss_rpn_cls: 0.005577  loss_rpn_loc: 0.001038  time: 0.5024  data_time: 0.0024  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:59:32 d2.utils.events]: \u001b[0m eta: 0:07:56  iter: 1539  total_loss: 0.4527  loss_cls: 0.1517  loss_box_reg: 0.2906  loss_rpn_cls: 0.004017  loss_rpn_loc: 0.001104  time: 0.5025  data_time: 0.0025  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:59:43 d2.utils.events]: \u001b[0m eta: 0:07:47  iter: 1559  total_loss: 0.4577  loss_cls: 0.167  loss_box_reg: 0.2684  loss_rpn_cls: 0.003005  loss_rpn_loc: 0.0009862  time: 0.5026  data_time: 0.0027  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 15:59:53 d2.utils.events]: \u001b[0m eta: 0:07:37  iter: 1579  total_loss: 0.4626  loss_cls: 0.1772  loss_box_reg: 0.2725  loss_rpn_cls: 0.006225  loss_rpn_loc: 0.001196  time: 0.5025  data_time: 0.0027  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:00:02 d2.utils.events]: \u001b[0m eta: 0:07:28  iter: 1599  total_loss: 0.4855  loss_cls: 0.1794  loss_box_reg: 0.2916  loss_rpn_cls: 0.004546  loss_rpn_loc: 0.00122  time: 0.5024  data_time: 0.0027  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:00:12 d2.utils.events]: \u001b[0m eta: 0:07:18  iter: 1619  total_loss: 0.4491  loss_cls: 0.1392  loss_box_reg: 0.2908  loss_rpn_cls: 0.004204  loss_rpn_loc: 0.00118  time: 0.5020  data_time: 0.0026  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:00:22 d2.utils.events]: \u001b[0m eta: 0:07:08  iter: 1639  total_loss: 0.4448  loss_cls: 0.1808  loss_box_reg: 0.2736  loss_rpn_cls: 0.00409  loss_rpn_loc: 0.0009281  time: 0.5018  data_time: 0.0026  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:00:31 d2.utils.events]: \u001b[0m eta: 0:06:58  iter: 1659  total_loss: 0.436  loss_cls: 0.1515  loss_box_reg: 0.271  loss_rpn_cls: 0.005556  loss_rpn_loc: 0.001076  time: 0.5015  data_time: 0.0025  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:00:41 d2.utils.events]: \u001b[0m eta: 0:06:49  iter: 1679  total_loss: 0.4213  loss_cls: 0.1561  loss_box_reg: 0.2596  loss_rpn_cls: 0.004989  loss_rpn_loc: 0.001463  time: 0.5015  data_time: 0.0027  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:00:51 d2.utils.events]: \u001b[0m eta: 0:06:39  iter: 1699  total_loss: 0.4427  loss_cls: 0.1636  loss_box_reg: 0.2693  loss_rpn_cls: 0.00569  loss_rpn_loc: 0.001354  time: 0.5014  data_time: 0.0027  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:01:01 d2.utils.events]: \u001b[0m eta: 0:06:29  iter: 1719  total_loss: 0.4152  loss_cls: 0.1631  loss_box_reg: 0.2461  loss_rpn_cls: 0.004048  loss_rpn_loc: 0.001343  time: 0.5013  data_time: 0.0027  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:01:11 d2.utils.events]: \u001b[0m eta: 0:06:19  iter: 1739  total_loss: 0.4167  loss_cls: 0.1493  loss_box_reg: 0.2722  loss_rpn_cls: 0.003011  loss_rpn_loc: 0.001218  time: 0.5011  data_time: 0.0026  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:01:20 d2.utils.events]: \u001b[0m eta: 0:06:09  iter: 1759  total_loss: 0.4392  loss_cls: 0.1624  loss_box_reg: 0.2828  loss_rpn_cls: 0.003806  loss_rpn_loc: 0.001282  time: 0.5010  data_time: 0.0027  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:01:30 d2.utils.events]: \u001b[0m eta: 0:05:59  iter: 1779  total_loss: 0.4203  loss_cls: 0.1533  loss_box_reg: 0.2784  loss_rpn_cls: 0.003875  loss_rpn_loc: 0.001107  time: 0.5008  data_time: 0.0026  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:01:40 d2.utils.events]: \u001b[0m eta: 0:05:50  iter: 1799  total_loss: 0.4459  loss_cls: 0.1631  loss_box_reg: 0.2845  loss_rpn_cls: 0.003068  loss_rpn_loc: 0.001186  time: 0.5008  data_time: 0.0025  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:01:50 d2.utils.events]: \u001b[0m eta: 0:05:39  iter: 1819  total_loss: 0.4039  loss_cls: 0.157  loss_box_reg: 0.2585  loss_rpn_cls: 0.003558  loss_rpn_loc: 0.001276  time: 0.5007  data_time: 0.0026  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:02:00 d2.utils.events]: \u001b[0m eta: 0:05:28  iter: 1839  total_loss: 0.4213  loss_cls: 0.1453  loss_box_reg: 0.2759  loss_rpn_cls: 0.004436  loss_rpn_loc: 0.0009873  time: 0.5007  data_time: 0.0026  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:02:10 d2.utils.events]: \u001b[0m eta: 0:05:18  iter: 1859  total_loss: 0.4074  loss_cls: 0.1574  loss_box_reg: 0.2627  loss_rpn_cls: 0.002889  loss_rpn_loc: 0.001226  time: 0.5006  data_time: 0.0025  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:02:20 d2.utils.events]: \u001b[0m eta: 0:05:08  iter: 1879  total_loss: 0.3875  loss_cls: 0.13  loss_box_reg: 0.253  loss_rpn_cls: 0.002904  loss_rpn_loc: 0.0008495  time: 0.5006  data_time: 0.0027  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:02:30 d2.utils.events]: \u001b[0m eta: 0:04:58  iter: 1899  total_loss: 0.3793  loss_cls: 0.1198  loss_box_reg: 0.2569  loss_rpn_cls: 0.002371  loss_rpn_loc: 0.00105  time: 0.5008  data_time: 0.0026  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:02:40 d2.utils.events]: \u001b[0m eta: 0:04:48  iter: 1919  total_loss: 0.3881  loss_cls: 0.1545  loss_box_reg: 0.2367  loss_rpn_cls: 0.002775  loss_rpn_loc: 0.001064  time: 0.5007  data_time: 0.0026  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:02:50 d2.utils.events]: \u001b[0m eta: 0:04:38  iter: 1939  total_loss: 0.4627  loss_cls: 0.157  loss_box_reg: 0.2786  loss_rpn_cls: 0.00307  loss_rpn_loc: 0.0009879  time: 0.5006  data_time: 0.0026  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:03:01 d2.utils.events]: \u001b[0m eta: 0:04:28  iter: 1959  total_loss: 0.4541  loss_cls: 0.1632  loss_box_reg: 0.2875  loss_rpn_cls: 0.004064  loss_rpn_loc: 0.001263  time: 0.5010  data_time: 0.0028  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:03:11 d2.utils.events]: \u001b[0m eta: 0:04:19  iter: 1979  total_loss: 0.3863  loss_cls: 0.1439  loss_box_reg: 0.2328  loss_rpn_cls: 0.002121  loss_rpn_loc: 0.000834  time: 0.5010  data_time: 0.0027  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:03:21 d2.utils.events]: \u001b[0m eta: 0:04:08  iter: 1999  total_loss: 0.4359  loss_cls: 0.1523  loss_box_reg: 0.2823  loss_rpn_cls: 0.002585  loss_rpn_loc: 0.0009026  time: 0.5009  data_time: 0.0026  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:03:30 d2.utils.events]: \u001b[0m eta: 0:03:59  iter: 2019  total_loss: 0.4018  loss_cls: 0.1392  loss_box_reg: 0.2559  loss_rpn_cls: 0.002614  loss_rpn_loc: 0.0009331  time: 0.5008  data_time: 0.0026  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:03:40 d2.utils.events]: \u001b[0m eta: 0:03:49  iter: 2039  total_loss: 0.3665  loss_cls: 0.1466  loss_box_reg: 0.2186  loss_rpn_cls: 0.002612  loss_rpn_loc: 0.001128  time: 0.5008  data_time: 0.0027  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:03:51 d2.utils.events]: \u001b[0m eta: 0:03:39  iter: 2059  total_loss: 0.3673  loss_cls: 0.1247  loss_box_reg: 0.2381  loss_rpn_cls: 0.002807  loss_rpn_loc: 0.0008336  time: 0.5008  data_time: 0.0027  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:04:01 d2.utils.events]: \u001b[0m eta: 0:03:29  iter: 2079  total_loss: 0.4064  loss_cls: 0.1357  loss_box_reg: 0.2592  loss_rpn_cls: 0.003906  loss_rpn_loc: 0.001132  time: 0.5008  data_time: 0.0026  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:04:10 d2.utils.events]: \u001b[0m eta: 0:03:19  iter: 2099  total_loss: 0.4049  loss_cls: 0.1409  loss_box_reg: 0.2647  loss_rpn_cls: 0.004068  loss_rpn_loc: 0.0009139  time: 0.5008  data_time: 0.0025  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:04:21 d2.utils.events]: \u001b[0m eta: 0:03:09  iter: 2119  total_loss: 0.3764  loss_cls: 0.1417  loss_box_reg: 0.2287  loss_rpn_cls: 0.002538  loss_rpn_loc: 0.0008165  time: 0.5010  data_time: 0.0028  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:04:31 d2.utils.events]: \u001b[0m eta: 0:02:59  iter: 2139  total_loss: 0.3798  loss_cls: 0.1267  loss_box_reg: 0.2406  loss_rpn_cls: 0.002738  loss_rpn_loc: 0.0009974  time: 0.5011  data_time: 0.0027  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:04:41 d2.utils.events]: \u001b[0m eta: 0:02:49  iter: 2159  total_loss: 0.4028  loss_cls: 0.1417  loss_box_reg: 0.2552  loss_rpn_cls: 0.002839  loss_rpn_loc: 0.0009497  time: 0.5009  data_time: 0.0026  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:04:51 d2.utils.events]: \u001b[0m eta: 0:02:39  iter: 2179  total_loss: 0.3893  loss_cls: 0.1159  loss_box_reg: 0.2465  loss_rpn_cls: 0.00223  loss_rpn_loc: 0.001102  time: 0.5009  data_time: 0.0026  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:05:01 d2.utils.events]: \u001b[0m eta: 0:02:29  iter: 2199  total_loss: 0.3722  loss_cls: 0.132  loss_box_reg: 0.2375  loss_rpn_cls: 0.002811  loss_rpn_loc: 0.001208  time: 0.5008  data_time: 0.0026  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:05:11 d2.utils.events]: \u001b[0m eta: 0:02:19  iter: 2219  total_loss: 0.4011  loss_cls: 0.1347  loss_box_reg: 0.2448  loss_rpn_cls: 0.003134  loss_rpn_loc: 0.001023  time: 0.5007  data_time: 0.0025  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:05:20 d2.utils.events]: \u001b[0m eta: 0:02:09  iter: 2239  total_loss: 0.3986  loss_cls: 0.1212  loss_box_reg: 0.2558  loss_rpn_cls: 0.003324  loss_rpn_loc: 0.001053  time: 0.5006  data_time: 0.0025  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:05:30 d2.utils.events]: \u001b[0m eta: 0:01:59  iter: 2259  total_loss: 0.3856  loss_cls: 0.1292  loss_box_reg: 0.2424  loss_rpn_cls: 0.002504  loss_rpn_loc: 0.001182  time: 0.5006  data_time: 0.0025  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:05:40 d2.utils.events]: \u001b[0m eta: 0:01:49  iter: 2279  total_loss: 0.3529  loss_cls: 0.1157  loss_box_reg: 0.2291  loss_rpn_cls: 0.003122  loss_rpn_loc: 0.001002  time: 0.5005  data_time: 0.0026  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:05:50 d2.utils.events]: \u001b[0m eta: 0:01:39  iter: 2299  total_loss: 0.3518  loss_cls: 0.116  loss_box_reg: 0.2362  loss_rpn_cls: 0.001975  loss_rpn_loc: 0.000922  time: 0.5005  data_time: 0.0025  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:06:01 d2.utils.events]: \u001b[0m eta: 0:01:29  iter: 2319  total_loss: 0.3699  loss_cls: 0.1162  loss_box_reg: 0.2418  loss_rpn_cls: 0.001813  loss_rpn_loc: 0.0008683  time: 0.5007  data_time: 0.0028  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:06:11 d2.utils.events]: \u001b[0m eta: 0:01:19  iter: 2339  total_loss: 0.3773  loss_cls: 0.1312  loss_box_reg: 0.2308  loss_rpn_cls: 0.002508  loss_rpn_loc: 0.001084  time: 0.5008  data_time: 0.0026  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:06:21 d2.utils.events]: \u001b[0m eta: 0:01:09  iter: 2359  total_loss: 0.3844  loss_cls: 0.1155  loss_box_reg: 0.2584  loss_rpn_cls: 0.002777  loss_rpn_loc: 0.0009715  time: 0.5008  data_time: 0.0026  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:06:31 d2.utils.events]: \u001b[0m eta: 0:00:59  iter: 2379  total_loss: 0.3725  loss_cls: 0.1325  loss_box_reg: 0.2478  loss_rpn_cls: 0.002052  loss_rpn_loc: 0.001094  time: 0.5007  data_time: 0.0028  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:06:40 d2.utils.events]: \u001b[0m eta: 0:00:49  iter: 2399  total_loss: 0.3654  loss_cls: 0.1201  loss_box_reg: 0.2373  loss_rpn_cls: 0.003538  loss_rpn_loc: 0.001084  time: 0.5006  data_time: 0.0026  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:06:50 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 2419  total_loss: 0.3487  loss_cls: 0.1205  loss_box_reg: 0.2205  loss_rpn_cls: 0.002488  loss_rpn_loc: 0.000646  time: 0.5005  data_time: 0.0025  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:07:00 d2.utils.events]: \u001b[0m eta: 0:00:29  iter: 2439  total_loss: 0.3857  loss_cls: 0.1326  loss_box_reg: 0.2481  loss_rpn_cls: 0.002199  loss_rpn_loc: 0.001007  time: 0.5004  data_time: 0.0029  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:07:10 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 2459  total_loss: 0.3464  loss_cls: 0.1104  loss_box_reg: 0.2182  loss_rpn_cls: 0.001543  loss_rpn_loc: 0.0009543  time: 0.5003  data_time: 0.0026  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:07:20 d2.utils.events]: \u001b[0m eta: 0:00:09  iter: 2479  total_loss: 0.3829  loss_cls: 0.1291  loss_box_reg: 0.2285  loss_rpn_cls: 0.003467  loss_rpn_loc: 0.001133  time: 0.5002  data_time: 0.0026  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:07:30 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 2499  total_loss: 0.3374  loss_cls: 0.1022  loss_box_reg: 0.2282  loss_rpn_cls: 0.002028  loss_rpn_loc: 0.0008331  time: 0.5002  data_time: 0.0026  lr: 0.00025  max_mem: 3156M\n",
      "\u001b[32m[10/11 16:07:30 d2.engine.hooks]: \u001b[0mOverall training speed: 2498 iterations in 0:20:49 (0.5002 s / it)\n",
      "\u001b[32m[10/11 16:07:30 d2.engine.hooks]: \u001b[0mTotal training time: 0:20:52 (0:00:03 on hooks)\n"
     ]
    }
   ],
   "source": [
    "wandb.init(sync_tensorboard=True,name='baseline')\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file('COCO-Detection/faster_rcnn_R_101_C4_3x.yaml'))\n",
    "cfg.DATASETS.TRAIN = ('data',)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.TEST.EVAL_PERIOD = 100\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url('COCO-Detection/faster_rcnn_R_101_C4_3x.yaml')\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.00025\n",
    "cfg.SOLVER.MAX_ITER = 2500\n",
    "cfg.SOLVER.STEPS = []\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d87385fe-d4bc-4fac-82ef-826f03ce9a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Could not find `tensorboard`. Please ensure that your PATH\n",
       "contains an executable `tensorboard` program, or explicitly specify\n",
       "the path to a TensorBoard binary by setting the `TENSORBOARD_BINARY`\n",
       "environment variable."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Look at training curves in tensorboard:\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e14b3b5d-3ea9-4475-8a01-39ed50a4af77",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set a custom testing threshold\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e47d322d-b6b1-422d-8488-656a804bc605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94410fa3-ce6f-49f6-8b93-e11af9263ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "im = cv2.imread('./data/vid_4_1000.jpg')\n",
    "outputs = predictor(im)\n",
    "v = Visualizer(im[:, :, ::-1],\n",
    "                metadata=metadata, \n",
    "               scale=0.5, \n",
    "               instance_mode=ColorMode.IMAGE_BW\n",
    "              )\n",
    "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.imshow(out.get_image()[:, :, ::-1])\n",
    "plt.savefig('./pred.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "242f0a75-ded6-4fff-b4e9-75e10f5e9e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/11 16:07:33 d2.evaluation.coco_evaluation]: \u001b[0m'data' is not registered by `register_coco_instances`. Therefore trying to convert it to COCO format ...\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/11 16:07:33 d2.data.datasets.coco]: \u001b[0mUsing previously cached COCO format annotations at './output/data_coco_format.json'. You need to clear the cache file if your dataset has been modified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 559/559 [00:02<00:00, 259.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/11 16:07:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/11 16:07:35 d2.data.common]: \u001b[0mSerializing 559 elements to byte tensors and concatenating them all ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/11 16:07:35 d2.data.common]: \u001b[0mSerialized dataset takes 0.19 MiB\n",
      "\u001b[32m[10/11 16:07:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 559 batches\n",
      "\u001b[32m[10/11 16:07:38 d2.evaluation.evaluator]: \u001b[0mInference done 11/559. Dataloading: 0.0009 s/iter. Inference: 0.2805 s/iter. Eval: 0.0001 s/iter. Total: 0.2816 s/iter. ETA=0:02:34\n",
      "\u001b[32m[10/11 16:07:43 d2.evaluation.evaluator]: \u001b[0mInference done 30/559. Dataloading: 0.0010 s/iter. Inference: 0.2740 s/iter. Eval: 0.0001 s/iter. Total: 0.2752 s/iter. ETA=0:02:25\n",
      "\u001b[32m[10/11 16:07:49 d2.evaluation.evaluator]: \u001b[0mInference done 50/559. Dataloading: 0.0010 s/iter. Inference: 0.2683 s/iter. Eval: 0.0001 s/iter. Total: 0.2695 s/iter. ETA=0:02:17\n",
      "\u001b[32m[10/11 16:07:54 d2.evaluation.evaluator]: \u001b[0mInference done 69/559. Dataloading: 0.0010 s/iter. Inference: 0.2677 s/iter. Eval: 0.0001 s/iter. Total: 0.2689 s/iter. ETA=0:02:11\n",
      "\u001b[32m[10/11 16:07:59 d2.evaluation.evaluator]: \u001b[0mInference done 89/559. Dataloading: 0.0010 s/iter. Inference: 0.2653 s/iter. Eval: 0.0001 s/iter. Total: 0.2665 s/iter. ETA=0:02:05\n",
      "\u001b[32m[10/11 16:08:04 d2.evaluation.evaluator]: \u001b[0mInference done 109/559. Dataloading: 0.0010 s/iter. Inference: 0.2646 s/iter. Eval: 0.0001 s/iter. Total: 0.2658 s/iter. ETA=0:01:59\n",
      "\u001b[32m[10/11 16:08:09 d2.evaluation.evaluator]: \u001b[0mInference done 128/559. Dataloading: 0.0010 s/iter. Inference: 0.2647 s/iter. Eval: 0.0001 s/iter. Total: 0.2659 s/iter. ETA=0:01:54\n",
      "\u001b[32m[10/11 16:08:14 d2.evaluation.evaluator]: \u001b[0mInference done 147/559. Dataloading: 0.0010 s/iter. Inference: 0.2647 s/iter. Eval: 0.0001 s/iter. Total: 0.2659 s/iter. ETA=0:01:49\n",
      "\u001b[32m[10/11 16:08:20 d2.evaluation.evaluator]: \u001b[0mInference done 167/559. Dataloading: 0.0009 s/iter. Inference: 0.2639 s/iter. Eval: 0.0001 s/iter. Total: 0.2651 s/iter. ETA=0:01:43\n",
      "\u001b[32m[10/11 16:08:25 d2.evaluation.evaluator]: \u001b[0mInference done 187/559. Dataloading: 0.0009 s/iter. Inference: 0.2633 s/iter. Eval: 0.0001 s/iter. Total: 0.2644 s/iter. ETA=0:01:38\n",
      "\u001b[32m[10/11 16:08:30 d2.evaluation.evaluator]: \u001b[0mInference done 207/559. Dataloading: 0.0009 s/iter. Inference: 0.2626 s/iter. Eval: 0.0001 s/iter. Total: 0.2638 s/iter. ETA=0:01:32\n",
      "\u001b[32m[10/11 16:08:35 d2.evaluation.evaluator]: \u001b[0mInference done 226/559. Dataloading: 0.0009 s/iter. Inference: 0.2633 s/iter. Eval: 0.0001 s/iter. Total: 0.2645 s/iter. ETA=0:01:28\n",
      "\u001b[32m[10/11 16:08:40 d2.evaluation.evaluator]: \u001b[0mInference done 245/559. Dataloading: 0.0009 s/iter. Inference: 0.2635 s/iter. Eval: 0.0001 s/iter. Total: 0.2646 s/iter. ETA=0:01:23\n",
      "\u001b[32m[10/11 16:08:45 d2.evaluation.evaluator]: \u001b[0mInference done 265/559. Dataloading: 0.0009 s/iter. Inference: 0.2630 s/iter. Eval: 0.0001 s/iter. Total: 0.2642 s/iter. ETA=0:01:17\n",
      "\u001b[32m[10/11 16:08:50 d2.evaluation.evaluator]: \u001b[0mInference done 285/559. Dataloading: 0.0009 s/iter. Inference: 0.2627 s/iter. Eval: 0.0001 s/iter. Total: 0.2638 s/iter. ETA=0:01:12\n",
      "\u001b[32m[10/11 16:08:56 d2.evaluation.evaluator]: \u001b[0mInference done 305/559. Dataloading: 0.0009 s/iter. Inference: 0.2623 s/iter. Eval: 0.0001 s/iter. Total: 0.2635 s/iter. ETA=0:01:06\n",
      "\u001b[32m[10/11 16:09:01 d2.evaluation.evaluator]: \u001b[0mInference done 325/559. Dataloading: 0.0009 s/iter. Inference: 0.2620 s/iter. Eval: 0.0001 s/iter. Total: 0.2632 s/iter. ETA=0:01:01\n",
      "\u001b[32m[10/11 16:09:06 d2.evaluation.evaluator]: \u001b[0mInference done 345/559. Dataloading: 0.0009 s/iter. Inference: 0.2619 s/iter. Eval: 0.0001 s/iter. Total: 0.2630 s/iter. ETA=0:00:56\n",
      "\u001b[32m[10/11 16:09:11 d2.evaluation.evaluator]: \u001b[0mInference done 364/559. Dataloading: 0.0009 s/iter. Inference: 0.2620 s/iter. Eval: 0.0001 s/iter. Total: 0.2632 s/iter. ETA=0:00:51\n",
      "\u001b[32m[10/11 16:09:16 d2.evaluation.evaluator]: \u001b[0mInference done 384/559. Dataloading: 0.0009 s/iter. Inference: 0.2618 s/iter. Eval: 0.0001 s/iter. Total: 0.2630 s/iter. ETA=0:00:46\n",
      "\u001b[32m[10/11 16:09:21 d2.evaluation.evaluator]: \u001b[0mInference done 404/559. Dataloading: 0.0009 s/iter. Inference: 0.2616 s/iter. Eval: 0.0001 s/iter. Total: 0.2628 s/iter. ETA=0:00:40\n",
      "\u001b[32m[10/11 16:09:27 d2.evaluation.evaluator]: \u001b[0mInference done 424/559. Dataloading: 0.0009 s/iter. Inference: 0.2615 s/iter. Eval: 0.0001 s/iter. Total: 0.2626 s/iter. ETA=0:00:35\n",
      "\u001b[32m[10/11 16:09:32 d2.evaluation.evaluator]: \u001b[0mInference done 444/559. Dataloading: 0.0009 s/iter. Inference: 0.2613 s/iter. Eval: 0.0001 s/iter. Total: 0.2624 s/iter. ETA=0:00:30\n",
      "\u001b[32m[10/11 16:09:37 d2.evaluation.evaluator]: \u001b[0mInference done 464/559. Dataloading: 0.0009 s/iter. Inference: 0.2611 s/iter. Eval: 0.0001 s/iter. Total: 0.2623 s/iter. ETA=0:00:24\n",
      "\u001b[32m[10/11 16:09:42 d2.evaluation.evaluator]: \u001b[0mInference done 484/559. Dataloading: 0.0009 s/iter. Inference: 0.2610 s/iter. Eval: 0.0001 s/iter. Total: 0.2621 s/iter. ETA=0:00:19\n",
      "\u001b[32m[10/11 16:09:47 d2.evaluation.evaluator]: \u001b[0mInference done 504/559. Dataloading: 0.0009 s/iter. Inference: 0.2608 s/iter. Eval: 0.0001 s/iter. Total: 0.2619 s/iter. ETA=0:00:14\n",
      "\u001b[32m[10/11 16:09:53 d2.evaluation.evaluator]: \u001b[0mInference done 524/559. Dataloading: 0.0009 s/iter. Inference: 0.2607 s/iter. Eval: 0.0001 s/iter. Total: 0.2619 s/iter. ETA=0:00:09\n",
      "\u001b[32m[10/11 16:09:58 d2.evaluation.evaluator]: \u001b[0mInference done 544/559. Dataloading: 0.0009 s/iter. Inference: 0.2606 s/iter. Eval: 0.0001 s/iter. Total: 0.2618 s/iter. ETA=0:00:03\n",
      "\u001b[32m[10/11 16:10:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:25.050188 (0.261823 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/11 16:10:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:02:24 (0.260479 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/11 16:10:02 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/11 16:10:02 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[10/11 16:10:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/11 16:10:02 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/11 16:10:02 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.05 seconds.\n",
      "\u001b[32m[10/11 16:10:02 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/11 16:10:02 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.142\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.325\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.109\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.142\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.218\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.477\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.477\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.477\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\u001b[32m[10/11 16:10:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:-----:|\n",
      "| 14.231 | 32.541 | 10.949 |  nan  | 14.232 |  nan  |\n",
      "\u001b[32m[10/11 16:10:02 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "OrderedDict([('bbox', {'AP': 14.231499182396451, 'AP50': 32.540611494107466, 'AP75': 10.948772913208936, 'APs': nan, 'APm': 14.231943583508649, 'APl': nan})])\n"
     ]
    }
   ],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "evaluator = COCOEvaluator(\"data\", output_dir=\"./output\")\n",
    "val_loader = build_detection_test_loader(cfg, \"data\")\n",
    "print(inference_on_dataset(predictor.model, val_loader, evaluator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9270c69e-03ba-4a65-91c8-493c06cb9b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/11 16:10:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 559 batches\n",
      "\u001b[32m[10/11 16:10:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/559. Dataloading: 0.0008 s/iter. Inference: 0.2593 s/iter. Eval: 0.0001 s/iter. Total: 0.2603 s/iter. ETA=0:02:22\n",
      "\u001b[32m[10/11 16:10:10 d2.evaluation.evaluator]: \u001b[0mInference done 31/559. Dataloading: 0.0009 s/iter. Inference: 0.2581 s/iter. Eval: 0.0001 s/iter. Total: 0.2593 s/iter. ETA=0:02:16\n",
      "\u001b[32m[10/11 16:10:15 d2.evaluation.evaluator]: \u001b[0mInference done 51/559. Dataloading: 0.0009 s/iter. Inference: 0.2582 s/iter. Eval: 0.0001 s/iter. Total: 0.2593 s/iter. ETA=0:02:11\n",
      "\u001b[32m[10/11 16:10:20 d2.evaluation.evaluator]: \u001b[0mInference done 71/559. Dataloading: 0.0009 s/iter. Inference: 0.2580 s/iter. Eval: 0.0001 s/iter. Total: 0.2591 s/iter. ETA=0:02:06\n",
      "\u001b[32m[10/11 16:10:25 d2.evaluation.evaluator]: \u001b[0mInference done 91/559. Dataloading: 0.0009 s/iter. Inference: 0.2575 s/iter. Eval: 0.0001 s/iter. Total: 0.2587 s/iter. ETA=0:02:01\n",
      "\u001b[32m[10/11 16:10:31 d2.evaluation.evaluator]: \u001b[0mInference done 111/559. Dataloading: 0.0009 s/iter. Inference: 0.2580 s/iter. Eval: 0.0001 s/iter. Total: 0.2592 s/iter. ETA=0:01:56\n",
      "\u001b[32m[10/11 16:10:36 d2.evaluation.evaluator]: \u001b[0mInference done 131/559. Dataloading: 0.0009 s/iter. Inference: 0.2580 s/iter. Eval: 0.0001 s/iter. Total: 0.2592 s/iter. ETA=0:01:50\n",
      "\u001b[32m[10/11 16:10:41 d2.evaluation.evaluator]: \u001b[0mInference done 151/559. Dataloading: 0.0009 s/iter. Inference: 0.2579 s/iter. Eval: 0.0001 s/iter. Total: 0.2591 s/iter. ETA=0:01:45\n",
      "\u001b[32m[10/11 16:10:46 d2.evaluation.evaluator]: \u001b[0mInference done 171/559. Dataloading: 0.0009 s/iter. Inference: 0.2580 s/iter. Eval: 0.0001 s/iter. Total: 0.2592 s/iter. ETA=0:01:40\n",
      "\u001b[32m[10/11 16:10:51 d2.evaluation.evaluator]: \u001b[0mInference done 191/559. Dataloading: 0.0009 s/iter. Inference: 0.2580 s/iter. Eval: 0.0001 s/iter. Total: 0.2592 s/iter. ETA=0:01:35\n",
      "\u001b[32m[10/11 16:10:57 d2.evaluation.evaluator]: \u001b[0mInference done 211/559. Dataloading: 0.0010 s/iter. Inference: 0.2578 s/iter. Eval: 0.0001 s/iter. Total: 0.2590 s/iter. ETA=0:01:30\n",
      "\u001b[32m[10/11 16:11:02 d2.evaluation.evaluator]: \u001b[0mInference done 231/559. Dataloading: 0.0010 s/iter. Inference: 0.2577 s/iter. Eval: 0.0001 s/iter. Total: 0.2589 s/iter. ETA=0:01:24\n",
      "\u001b[32m[10/11 16:11:07 d2.evaluation.evaluator]: \u001b[0mInference done 251/559. Dataloading: 0.0010 s/iter. Inference: 0.2576 s/iter. Eval: 0.0001 s/iter. Total: 0.2588 s/iter. ETA=0:01:19\n",
      "\u001b[32m[10/11 16:11:12 d2.evaluation.evaluator]: \u001b[0mInference done 271/559. Dataloading: 0.0010 s/iter. Inference: 0.2575 s/iter. Eval: 0.0001 s/iter. Total: 0.2587 s/iter. ETA=0:01:14\n",
      "\u001b[32m[10/11 16:11:17 d2.evaluation.evaluator]: \u001b[0mInference done 291/559. Dataloading: 0.0010 s/iter. Inference: 0.2575 s/iter. Eval: 0.0001 s/iter. Total: 0.2587 s/iter. ETA=0:01:09\n",
      "\u001b[32m[10/11 16:11:22 d2.evaluation.evaluator]: \u001b[0mInference done 311/559. Dataloading: 0.0010 s/iter. Inference: 0.2574 s/iter. Eval: 0.0001 s/iter. Total: 0.2586 s/iter. ETA=0:01:04\n",
      "\u001b[32m[10/11 16:11:28 d2.evaluation.evaluator]: \u001b[0mInference done 331/559. Dataloading: 0.0010 s/iter. Inference: 0.2574 s/iter. Eval: 0.0001 s/iter. Total: 0.2586 s/iter. ETA=0:00:58\n",
      "\u001b[32m[10/11 16:11:33 d2.evaluation.evaluator]: \u001b[0mInference done 351/559. Dataloading: 0.0010 s/iter. Inference: 0.2574 s/iter. Eval: 0.0001 s/iter. Total: 0.2586 s/iter. ETA=0:00:53\n",
      "\u001b[32m[10/11 16:11:38 d2.evaluation.evaluator]: \u001b[0mInference done 371/559. Dataloading: 0.0010 s/iter. Inference: 0.2575 s/iter. Eval: 0.0001 s/iter. Total: 0.2587 s/iter. ETA=0:00:48\n",
      "\u001b[32m[10/11 16:11:43 d2.evaluation.evaluator]: \u001b[0mInference done 391/559. Dataloading: 0.0010 s/iter. Inference: 0.2574 s/iter. Eval: 0.0001 s/iter. Total: 0.2586 s/iter. ETA=0:00:43\n",
      "\u001b[32m[10/11 16:11:48 d2.evaluation.evaluator]: \u001b[0mInference done 411/559. Dataloading: 0.0010 s/iter. Inference: 0.2574 s/iter. Eval: 0.0001 s/iter. Total: 0.2586 s/iter. ETA=0:00:38\n",
      "\u001b[32m[10/11 16:11:53 d2.evaluation.evaluator]: \u001b[0mInference done 431/559. Dataloading: 0.0010 s/iter. Inference: 0.2574 s/iter. Eval: 0.0001 s/iter. Total: 0.2586 s/iter. ETA=0:00:33\n",
      "\u001b[32m[10/11 16:11:59 d2.evaluation.evaluator]: \u001b[0mInference done 451/559. Dataloading: 0.0010 s/iter. Inference: 0.2573 s/iter. Eval: 0.0001 s/iter. Total: 0.2586 s/iter. ETA=0:00:27\n",
      "\u001b[32m[10/11 16:12:04 d2.evaluation.evaluator]: \u001b[0mInference done 471/559. Dataloading: 0.0010 s/iter. Inference: 0.2574 s/iter. Eval: 0.0001 s/iter. Total: 0.2586 s/iter. ETA=0:00:22\n",
      "\u001b[32m[10/11 16:12:09 d2.evaluation.evaluator]: \u001b[0mInference done 491/559. Dataloading: 0.0010 s/iter. Inference: 0.2574 s/iter. Eval: 0.0001 s/iter. Total: 0.2586 s/iter. ETA=0:00:17\n",
      "\u001b[32m[10/11 16:12:14 d2.evaluation.evaluator]: \u001b[0mInference done 511/559. Dataloading: 0.0010 s/iter. Inference: 0.2573 s/iter. Eval: 0.0001 s/iter. Total: 0.2585 s/iter. ETA=0:00:12\n",
      "\u001b[32m[10/11 16:12:19 d2.evaluation.evaluator]: \u001b[0mInference done 531/559. Dataloading: 0.0010 s/iter. Inference: 0.2573 s/iter. Eval: 0.0001 s/iter. Total: 0.2585 s/iter. ETA=0:00:07\n",
      "\u001b[32m[10/11 16:12:24 d2.evaluation.evaluator]: \u001b[0mInference done 551/559. Dataloading: 0.0010 s/iter. Inference: 0.2573 s/iter. Eval: 0.0001 s/iter. Total: 0.2585 s/iter. ETA=0:00:02\n",
      "\u001b[32m[10/11 16:12:26 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:23.240711 (0.258557 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/11 16:12:26 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:02:22 (0.257203 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/11 16:12:26 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/11 16:12:26 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[10/11 16:12:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/11 16:12:27 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/11 16:12:27 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.04 seconds.\n",
      "\u001b[32m[10/11 16:12:27 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/11 16:12:27 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.142\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.325\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.109\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.142\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.218\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.477\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.477\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.477\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\u001b[32m[10/11 16:12:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:-----:|\n",
      "| 14.231 | 32.541 | 10.949 |  nan  | 14.232 |  nan  |\n",
      "\u001b[32m[10/11 16:12:27 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n"
     ]
    }
   ],
   "source": [
    "wandb.log({'coco':inference_on_dataset(predictor.model, val_loader, evaluator)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d27d486-0d12-40ee-a75c-5da5302dfb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/11 16:12:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 559 batches\n",
      "\u001b[32m[10/11 16:12:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/559. Dataloading: 0.0008 s/iter. Inference: 0.2559 s/iter. Eval: 0.0001 s/iter. Total: 0.2568 s/iter. ETA=0:02:20\n",
      "\u001b[32m[10/11 16:12:35 d2.evaluation.evaluator]: \u001b[0mInference done 31/559. Dataloading: 0.0010 s/iter. Inference: 0.2585 s/iter. Eval: 0.0001 s/iter. Total: 0.2597 s/iter. ETA=0:02:17\n",
      "\u001b[32m[10/11 16:12:40 d2.evaluation.evaluator]: \u001b[0mInference done 51/559. Dataloading: 0.0010 s/iter. Inference: 0.2580 s/iter. Eval: 0.0001 s/iter. Total: 0.2592 s/iter. ETA=0:02:11\n",
      "\u001b[32m[10/11 16:12:45 d2.evaluation.evaluator]: \u001b[0mInference done 71/559. Dataloading: 0.0010 s/iter. Inference: 0.2568 s/iter. Eval: 0.0001 s/iter. Total: 0.2580 s/iter. ETA=0:02:05\n",
      "\u001b[32m[10/11 16:12:50 d2.evaluation.evaluator]: \u001b[0mInference done 90/559. Dataloading: 0.0010 s/iter. Inference: 0.2582 s/iter. Eval: 0.0001 s/iter. Total: 0.2594 s/iter. ETA=0:02:01\n",
      "\u001b[32m[10/11 16:12:55 d2.evaluation.evaluator]: \u001b[0mInference done 110/559. Dataloading: 0.0010 s/iter. Inference: 0.2576 s/iter. Eval: 0.0001 s/iter. Total: 0.2588 s/iter. ETA=0:01:56\n",
      "\u001b[32m[10/11 16:13:00 d2.evaluation.evaluator]: \u001b[0mInference done 130/559. Dataloading: 0.0010 s/iter. Inference: 0.2576 s/iter. Eval: 0.0001 s/iter. Total: 0.2587 s/iter. ETA=0:01:51\n",
      "\u001b[32m[10/11 16:13:05 d2.evaluation.evaluator]: \u001b[0mInference done 150/559. Dataloading: 0.0010 s/iter. Inference: 0.2573 s/iter. Eval: 0.0001 s/iter. Total: 0.2585 s/iter. ETA=0:01:45\n",
      "\u001b[32m[10/11 16:13:11 d2.evaluation.evaluator]: \u001b[0mInference done 170/559. Dataloading: 0.0009 s/iter. Inference: 0.2573 s/iter. Eval: 0.0001 s/iter. Total: 0.2584 s/iter. ETA=0:01:40\n",
      "\u001b[32m[10/11 16:13:16 d2.evaluation.evaluator]: \u001b[0mInference done 190/559. Dataloading: 0.0009 s/iter. Inference: 0.2573 s/iter. Eval: 0.0001 s/iter. Total: 0.2585 s/iter. ETA=0:01:35\n",
      "\u001b[32m[10/11 16:13:21 d2.evaluation.evaluator]: \u001b[0mInference done 210/559. Dataloading: 0.0010 s/iter. Inference: 0.2573 s/iter. Eval: 0.0001 s/iter. Total: 0.2585 s/iter. ETA=0:01:30\n",
      "\u001b[32m[10/11 16:13:26 d2.evaluation.evaluator]: \u001b[0mInference done 230/559. Dataloading: 0.0010 s/iter. Inference: 0.2572 s/iter. Eval: 0.0001 s/iter. Total: 0.2584 s/iter. ETA=0:01:25\n",
      "\u001b[32m[10/11 16:13:31 d2.evaluation.evaluator]: \u001b[0mInference done 250/559. Dataloading: 0.0010 s/iter. Inference: 0.2570 s/iter. Eval: 0.0001 s/iter. Total: 0.2582 s/iter. ETA=0:01:19\n",
      "\u001b[32m[10/11 16:13:36 d2.evaluation.evaluator]: \u001b[0mInference done 270/559. Dataloading: 0.0010 s/iter. Inference: 0.2570 s/iter. Eval: 0.0001 s/iter. Total: 0.2582 s/iter. ETA=0:01:14\n",
      "\u001b[32m[10/11 16:13:42 d2.evaluation.evaluator]: \u001b[0mInference done 290/559. Dataloading: 0.0010 s/iter. Inference: 0.2569 s/iter. Eval: 0.0001 s/iter. Total: 0.2581 s/iter. ETA=0:01:09\n",
      "\u001b[32m[10/11 16:13:47 d2.evaluation.evaluator]: \u001b[0mInference done 310/559. Dataloading: 0.0010 s/iter. Inference: 0.2571 s/iter. Eval: 0.0001 s/iter. Total: 0.2583 s/iter. ETA=0:01:04\n",
      "\u001b[32m[10/11 16:13:52 d2.evaluation.evaluator]: \u001b[0mInference done 330/559. Dataloading: 0.0010 s/iter. Inference: 0.2571 s/iter. Eval: 0.0001 s/iter. Total: 0.2583 s/iter. ETA=0:00:59\n",
      "\u001b[32m[10/11 16:13:57 d2.evaluation.evaluator]: \u001b[0mInference done 350/559. Dataloading: 0.0010 s/iter. Inference: 0.2571 s/iter. Eval: 0.0001 s/iter. Total: 0.2583 s/iter. ETA=0:00:53\n",
      "\u001b[32m[10/11 16:14:02 d2.evaluation.evaluator]: \u001b[0mInference done 370/559. Dataloading: 0.0010 s/iter. Inference: 0.2570 s/iter. Eval: 0.0001 s/iter. Total: 0.2582 s/iter. ETA=0:00:48\n",
      "\u001b[32m[10/11 16:14:07 d2.evaluation.evaluator]: \u001b[0mInference done 390/559. Dataloading: 0.0010 s/iter. Inference: 0.2569 s/iter. Eval: 0.0001 s/iter. Total: 0.2581 s/iter. ETA=0:00:43\n",
      "\u001b[32m[10/11 16:14:13 d2.evaluation.evaluator]: \u001b[0mInference done 410/559. Dataloading: 0.0010 s/iter. Inference: 0.2569 s/iter. Eval: 0.0001 s/iter. Total: 0.2581 s/iter. ETA=0:00:38\n",
      "\u001b[32m[10/11 16:14:18 d2.evaluation.evaluator]: \u001b[0mInference done 430/559. Dataloading: 0.0010 s/iter. Inference: 0.2570 s/iter. Eval: 0.0001 s/iter. Total: 0.2582 s/iter. ETA=0:00:33\n",
      "\u001b[32m[10/11 16:14:23 d2.evaluation.evaluator]: \u001b[0mInference done 450/559. Dataloading: 0.0010 s/iter. Inference: 0.2569 s/iter. Eval: 0.0001 s/iter. Total: 0.2581 s/iter. ETA=0:00:28\n",
      "\u001b[32m[10/11 16:14:28 d2.evaluation.evaluator]: \u001b[0mInference done 470/559. Dataloading: 0.0010 s/iter. Inference: 0.2568 s/iter. Eval: 0.0001 s/iter. Total: 0.2580 s/iter. ETA=0:00:22\n",
      "\u001b[32m[10/11 16:14:33 d2.evaluation.evaluator]: \u001b[0mInference done 490/559. Dataloading: 0.0010 s/iter. Inference: 0.2568 s/iter. Eval: 0.0001 s/iter. Total: 0.2580 s/iter. ETA=0:00:17\n",
      "\u001b[32m[10/11 16:14:38 d2.evaluation.evaluator]: \u001b[0mInference done 510/559. Dataloading: 0.0010 s/iter. Inference: 0.2568 s/iter. Eval: 0.0001 s/iter. Total: 0.2580 s/iter. ETA=0:00:12\n",
      "\u001b[32m[10/11 16:14:44 d2.evaluation.evaluator]: \u001b[0mInference done 530/559. Dataloading: 0.0010 s/iter. Inference: 0.2570 s/iter. Eval: 0.0001 s/iter. Total: 0.2581 s/iter. ETA=0:00:07\n",
      "\u001b[32m[10/11 16:14:49 d2.evaluation.evaluator]: \u001b[0mInference done 548/559. Dataloading: 0.0010 s/iter. Inference: 0.2577 s/iter. Eval: 0.0001 s/iter. Total: 0.2589 s/iter. ETA=0:00:02\n",
      "\u001b[32m[10/11 16:14:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:23.714942 (0.259413 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/11 16:14:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:02:22 (0.258048 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/11 16:14:52 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/11 16:14:52 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[10/11 16:14:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/11 16:14:52 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/11 16:14:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.04 seconds.\n",
      "\u001b[32m[10/11 16:14:52 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/11 16:14:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.142\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.325\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.109\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.142\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.218\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.477\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.477\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.477\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\u001b[32m[10/11 16:14:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:-----:|\n",
      "| 14.231 | 32.541 | 10.949 |  nan  | 14.232 |  nan  |\n",
      "\u001b[32m[10/11 16:14:52 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n"
     ]
    }
   ],
   "source": [
    "wandb.log(inference_on_dataset(predictor.model, val_loader, evaluator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95911805-2e1d-4117-8e7e-6668aa26483b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('myenv': conda)",
   "language": "python",
   "name": "python3811jvsc74a57bd0f5712b28ab533ddcd3a93c4a815f0ece6a0b0b411aefcf33cd4d282335a68ea6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
